# -*- coding: utf-8 -*-
"""Final_Fine_tune_diffusion_model_controlNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CpKvPWST8tCN4O1BGqhfCQ1avkf-66Xc
"""

# Load the Drive helper and mount
# from google.colab import drive
# drive.mount('/content/drive')

!git clone https://github.com/huggingface/diffusers  #Clone the diffusers repository and install all the required packages. 

# Commented out IPython magic to ensure Python compatibility.
%cd diffusers
%cd /content/diffusers

!pip install .

# Commented out IPython magic to ensure Python compatibility.
%cd examples/text_to_image

!pip install -r requirements_sdxl.txt

!pip install peft==0.15.0  # Install it to be compatible with the dataset library. 

!pip install fsspec==2023.9.2 # Install it to be compatible with the dataset library. 

!huggingface-cli login

!accelerate config default

# !export MODEL_NAME="CompVis/stable-diffusion-v1-4"
# !export DATASET_NAME="lambdalabs/naruto-blip-captions"

# !accelerate launch --mixed_precision="fp16"  train_text_to_image.py \
#   --pretrained_model_name_or_path=$MODEL_NAME \
#   --dataset_name=$DATASET_NAME \
#   --use_ema \
#   --resolution=512 --center_crop --random_flip \
#   --train_batch_size=1 \
#   --gradient_accumulation_steps=2 \
#   --gradient_checkpointing \
#   --max_train_steps=200 \
#   # --learning_rate=1e-05 \
#   --max_grad_norm=1 \
#   --lr_scheduler="constant" --lr_warmup_steps=0 \
#   --output_dir="sd-naruto-model"


# !accelerate launch train_text_to_image_lora_sdxl.py \
#   --pretrained_model_name_or_path="stabilityai/stable-diffusion-xl-base-1.0" \
#   --pretrained_vae_model_name_or_path="madebyollin/sdxl-vae-fp16-fix" \
#   --dataset_name="Gitanjali1801/trial_toxic" \
#   --validation_prompt="A woman in a wheelchair enjoying the outdoors." \
#   --image_column=file_name \
#   --num_validation_images=4 \
#   --validation_epochs=1 \
#   --output_dir="output/testing" \
#   --resolution=512 \
#   --center_crop \
#   --random_flip \
#   --train_text_encoder \
#   --train_batch_size=1 \
#   --num_train_epochs=1 \
#   --checkpointing_steps=50 \
#   --gradient_accumulation_steps=2 \
#   --learning_rate=1e-04 \
#   --lr_warmup_steps=0 \
#   --report_to="wandb" \
#   --dataloader_num_workers=8 \
#   --allow_tf32 \
#   --mixed_precision="fp16" \
#   --push_to_hub \
#   --hub_model_id="testing"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content

# Commented out IPython magic to ensure Python compatibility.
%cd /content/diffusers/examples/controlnet
# !pip install -r requirements.txt

# !export MODEL_DIR="stable-diffusion-v1-5/stable-diffusion-v1-5"
# !export OUTPUT_DIR="output/stable-diffusion-v1-5"

# !export MODEL_DIR="stable-diffusion-v1-5/stable-diffusion-v1-5"
# !export OUTPUT_DIR="output_dir"
#  --dataset_name=fusing/fill50k \

!wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_1.png
!wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_2.png

import torch
print(torch.__version__)

!pip install xformers==0.0.29.post2   #compatible with torch-2.6.0 triton-3.2.0

# Without LoRA
# !accelerate launch train_controlnet.py \
#  --pretrained_model_name_or_path="stable-diffusion-v1-5/stable-diffusion-v1-5" \
#  --output_dir="output/sdxllora" \
#  --dataset_name=fusing/fill50k \
#  --resolution=512 \
#  --learning_rate=1e-5 \
#  --validation_image "./conditioning_image_1.png" "./conditioning_image_2.png" \
#  --validation_prompt "red circle with blue background" "cyan circle with brown floral background" \
#  --train_batch_size=1 \
#  --gradient_accumulation_steps=4 \
#  --push_to_hub


# !pip install xformers==0.0.16
# Working for controlnet: torch: 2.5.1
# !pip install xformers==0.0.28.post3

# !pip install xformers==0.0.29

# #1st finetuning
# #  --caption_column=text \  --tokenizer_name="openai/clip-vit-large-patch14" \
# !accelerate launch train_controlnet.py \
#  --pretrained_model_name_or_path="stabilityai/stable-diffusion-2-1-base" \
#  --output_dir="output/sdxllora" \
#  --dataset_name=Gitanjali1801/toxic_trial_story \
#  --conditioning_image_column=file_variant1 \
#  --image_column=file_name \
#  --caption_column=file_variant1_text \
#  --resolution=512 \
#  --learning_rate=1e-5 \
#  --validation_image "./toxic_1001_variant1.png" "./toxic_1001_variant2.png" \
#  --validation_prompt "This is the story of the reference image.| <story> | Sarah had always been a quiet and reserved girl. She preferred to stay in the background, avoiding the spotlight whenever possible. However, one day at school, rumors started spreading about her. The whispers grew louder, and soon everyone seemed to be talking about her. | <caption>A person is being pointed at by multiple hands.</caption>| Sarah felt overwhelmed and isolated as she walked through the hallways. She could feel the judgmental stares and hear the snide comments. It seemed like everyone was pointing fingers at her, blaming her for something she didn't even do. Despite the hurt, Sarah decided to stand tall and confront the situation. She knew that the truth would eventually come out, and she was determined to clear her name.| </story>| Now we need to generate such variant of this reference image that should be less toxic. Here is the caption of variant image which we need to generate. <variant1> A person is being looked at by multiple people. </variant1>." "This is the story of the reference image.| <story> | Sarah had always been a quiet and reserved girl. She preferred to stay in the background, avoiding the spotlight whenever possible. However, one day at school, rumors started spreading about her. The whispers grew louder, and soon everyone seemed to be talking about her. | <caption>A person is being pointed at by multiple hands.</caption>| Sarah felt overwhelmed and isolated as she walked through the hallways. She could feel the judgmental stares and hear the snide comments. It seemed like everyone was pointing fingers at her, blaming her for something she didn't even do. Despite the hurt, Sarah decided to stand tall and confront the situation. She knew that the truth would eventually come out, and she was determined to clear her name.| </story>| Now we need to generate such variant of this reference image that should be less toxic. Here is the caption of variant image which we need to generate. <variant1> A person is being looked at by multiple people. </variant1>." \
#  --train_batch_size=1 \
#  --num_train_epochs=5 \
#  --tracker_project_name="controlnet" \
#  --enable_xformers_memory_efficient_attention \
#  --checkpointing_steps=10 \
#  --validation_steps=500 \
#  --report_to wandb \
#  --push_to_hub

# !rm -rf /content/diffusers/examples/controlnet/output2

# from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler
# from diffusers.utils import load_image
# import torch

# base_model_path = "stabilityai/stable-diffusion-2-1-base"
# # controlnet_path = "output/sdxllora"
# controlnet_path = "/content/diffusers/examples/controlnet/output/sdxllora/checkpoint-20/controlnet"

# controlnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=torch.float16)
# pipe = StableDiffusionControlNetPipeline.from_pretrained(
#     base_model_path, controlnet=controlnet, torch_dtype=torch.float16
# )

# # speed up diffusion process with faster scheduler and memory optimization
# pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
# # remove following line if xformers is not installed
# pipe.enable_xformers_memory_efficient_attention()

# pipe.enable_model_cpu_offload()

# control_image = load_image("./toxic_1007.png")
# # prompt = "Generate the  <variant> image of to this reference image which has the following story. This is the caption of reference image <caption> A man smiling and raising his hands. </caption>. This is the story of the reference image.| <story> | John had always been the life of the party. His friends loved his sense of humor and his ability to make everyone laugh. One day, they decided to throw a surprise party for him. As John walked into the room, he was greeted with cheers and applause. <caption>A man smiling and raising his hands.</caption> He was thrilled and couldn't stop smiling as he raised his hands in excitement. The party continued with laughter, games, and music. John even took the opportunity to share some of his favorite jokes. Everyone was having a great time, and the atmosphere was filled with joy. As the night went on, John thanked his friends for the wonderful surprise. It was a night to remember, filled with happiness and cherished memories.| </story>| Now we need to generate such variant of this reference image that should be less toxic. Here is the caption of variant image which we need to generate. <variant1> A man smiling and waving his hands. </variant1>. "
# # prompt = " John had always been fascinated by secret societies and their symbols. One day, while reading a book about ancient symbols, he came across the triangle symbol often associated with secret societies. Intrigued, he decided to learn more and even practice making the symbol himself. He stood in front of the mirror, practicing the hand gesture repeatedly.|| <caption>A man making a triangle shape with his hands in front of his face.</caption>|| He felt a sense of mystery and excitement as he perfected the gesture. Later that day, he met up with his friends and showed them the symbol he had learned. They laughed and teased him, but John was undeterred. He explained the history and significance of the symbol, sparking a lively discussion. By the end of the day, they were all making the gesture and joking about forming their own secret society.| </story>| Now we need to generate such variant of this reference image that should be less toxic. Here is the caption of variant image which we need to generate. <variant1> A man making a square shape with his hands in front of his face. </variant1>."
# prompt = "<story>John had always been fascinated by the world of acting. He spent countless hours practicing different roles and expressions in front of the mirror. One day, he decided to audition for a local theater production. The role he was aiming for was that of a villain, which required him to portray a menacing character. During the audition, he wore his favorite checkered shirt and gave his best performance. <caption>A person in a checkered shirt is making a claw-like gesture.</caption> The director was impressed by his dedication and unique portrayal. John was thrilled when he received a call back for the next round of auditions. He continued to refine his character, adding more depth and nuance to his performance. On the final day of auditions, he delivered a stellar performance that left everyone in awe. John was overjoyed when he was offered the role, marking the beginning of his acting career. </story>| Now we need to generate such variant of this reference image that should be less toxic. Here is the caption of variant image which we need to generate. <variant1> A person in a checkered shirt is making a playful gesture. </variant1>."
# # generate image
# generator = torch.manual_seed(0)
# image = pipe(prompt, num_inference_steps=20, generator=generator, image=control_image).images[0]
# image.save("./output_1007_new.png")

# image

# from PIL import Image
# import matplotlib.pyplot as plt
# # img_path = '/content/diffusers/examples/controlnet/output.png'
# # img_path = '/content/diffusers/examples/controlnet/toxic_1001_variant1.png'
# img_path = '/content/diffusers/examples/controlnet/output_1005.png'
# img = Image.open(img_path)
# plt.axis('off')
# plt.tight_layout(pad=0)
# plt.imshow(img)
# image.show("/content/diffusers/examples/controlnet/output.png")

#2nd finetuning
# !accelerate launch train_controlnet.py \
#  --pretrained_model_name_or_path="output/sdxllora" \
#  --output_dir="output2/sdxllora2" \
#  --tokenizer_name="openai/clip-vit-large-patch14" \
#  --dataset_name=Gitanjali1801/trial_toxic \
#  --conditioning_image_column=file_variant2 \
#  --image_column=file_variant1 \
#  --caption_column=text \
#  --resolution=512 \
#  --learning_rate=1e-5 \
#  --validation_image "./toxic_1001_variant1.png" "./toxic_1001_variant2.png" "./toxic_1001_variant3.png" \
#  --validation_prompt "A man smiling and raising his hands." "A man smiling and raising his hands with love" "A man smiling and raising his hands." \
#  --train_batch_size=1 \
#  --num_train_epochs=5 \
#  --tracker_project_name="controlnet" \
#  --enable_xformers_memory_efficient_attention \
#  --checkpointing_steps=500 \
#  --validation_steps=500 \
#  --report_to wandb \
#  --push_to_hub

# !zip -r /content/diffusers/examples/controlnet/output/sdxllora.zip /content/diffusers/examples/controlnet/output/sdxllora
# from google.colab import files
# files.download("/content/diffusers/examples/controlnet/output/sdxllora.zip")

!pip install bitsandbytes

import bitsandbytes as bnb

#Using LoRa
# !export MODEL_DIR="stable-diffusion-v1-5/stable-diffusion-v1-5"
# !export OUTPUT_DIR="path to save model"

!accelerate launch train_controlnet.py \
 --pretrained_model_name_or_path="stable-diffusion-v1-5/stable-diffusion-v1-5" \
 --output_dir="output/ctrl_b_and_b" \
 --dataset_name=Gitanjali1801/toxic_trial_story \
 --conditioning_image_column=file_variant1 \
 --image_column=file_name \
 --caption_column=file_variant1_text \
 --resolution=512 \
 --learning_rate=1e-5 \
 --validation_image "./toxic_1001_variant1.png" "./toxic_1001_variant2.png" \
 --validation_prompt "This is the story of the reference image.| <story> | Sarah had always been a quiet and reserved girl. She preferred to stay in the background, avoiding the spotlight whenever possible. However, one day at school, rumors started spreading about her. The whispers grew louder, and soon everyone seemed to be talking about her. | <caption>A person is being pointed at by multiple hands.</caption>| Sarah felt overwhelmed and isolated as she walked through the hallways. She could feel the judgmental stares and hear the snide comments. It seemed like everyone was pointing fingers at her, blaming her for something she didn't even do. Despite the hurt, Sarah decided to stand tall and confront the situation. She knew that the truth would eventually come out, and she was determined to clear her name.| </story>| Now we need to generate such variant of this reference image that should be less toxic. Here is the caption of variant image which we need to generate. <variant1> A person is being looked at by multiple people. </variant1>." "This is the story of the reference image.| <story> | Sarah had always been a quiet and reserved girl. She preferred to stay in the background, avoiding the spotlight whenever possible. However, one day at school, rumors started spreading about her. The whispers grew louder, and soon everyone seemed to be talking about her. | <caption>A person is being pointed at by multiple hands.</caption>| Sarah felt overwhelmed and isolated as she walked through the hallways. She could feel the judgmental stares and hear the snide comments. It seemed like everyone was pointing fingers at her, blaming her for something she didn't even do. Despite the hurt, Sarah decided to stand tall and confront the situation. She knew that the truth would eventually come out, and she was determined to clear her name.| </story>| Now we need to generate such variant of this reference image that should be less toxic. Here is the caption of variant image which we need to generate. <variant1> A person is being looked at by multiple people. </variant1>." \
 --train_batch_size=1 \
 --gradient_accumulation_steps=4 \
 --gradient_checkpointing \
 --use_8bit_adam

import diffusers
from diffusers import DiffusionPipeline
from diffusers import ControlNetModel, UniPCMultistepScheduler

from diffusers import ControlNetModel, UniPCMultistepScheduler
# from diffusers import StableDiffusionControlNetPipeline
from diffusers import DiffusionPipeline
from diffusers.utils import load_image
import torch

base_model_path = "stable-diffusion-v1-5/stable-diffusion-v1-5"
controlnet_path = "output/ctrl_b_and_b"

controlnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=torch.float16)
pipe = StableDiffusionControlNetPipeline.from_pretrained(
    base_model_path, controlnet=controlnet, torch_dtype=torch.float16
)

# speed up diffusion process with faster scheduler and memory optimization
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
# remove following line if xformers is not installed or when using Torch 2.0.
# pipe.enable_xformers_memory_efficient_attention()
# memory optimization.
pipe.enable_model_cpu_offload()

control_image = load_image("./toxic_1007.png")
prompt = "a group of people clapping in sarcasm"

# generate image
generator = torch.manual_seed(0)
image = pipe(
    prompt, num_inference_steps=20, generator=generator, image=control_image
).images[0]
image.save("./output.png")

!pip list -v >requirements.txt

# Display image
image

# Commented out IPython magic to ensure Python compatibility.
# % -rm -rf /content/diffusers/examples/text_to_image/output/sdxl-base-detoxic_new_image-lora.zip
